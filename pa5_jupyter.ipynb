{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import *\n",
    "from load_data import *\n",
    "import dlib\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # Task 1 \n",
    "    model = FAN(4)\n",
    "    model.build((1,256,256,3))\n",
    "    model.load_weights(\"tf_fan_2D_3layers.h5\")\n",
    "\n",
    "    model.base.trainable = False # Freezes the weights for the base module\n",
    "    for i in range(3):\n",
    "        # TODO: Freeze the weights for the first 3 hourglass modules\n",
    "        # Each hourglass module is composed of elements from\n",
    "        # model.hgs, model.ls, model.split_as, model.split_bs\n",
    "        model.hgs[i].trainable = False \n",
    "        model.ls[i].trainable = False \n",
    "        model.split_as[i].trainable = False \n",
    "        model.split_bs[i].trainable = False \n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def heatmap_k(x_k, y_k, k):\n",
    "    return np.array([math.exp(-((x - x_k)**2 + (y - y_k)**2)) for x in range(64) for y in range(64)]).reshape((64, 64))\n",
    "\n",
    "def generate_heatmaps(resized_landmarks):\n",
    "    resize_ratio = 64/256\n",
    "    heatmap_landmarks = np.round(resize_ratio * resized_landmarks)\n",
    "    heatmaps = []\n",
    "    for k in range(heatmap_landmarks.shape[0]):\n",
    "        x_k = heatmap_landmarks[k, 0]\n",
    "        y_k = heatmap_landmarks[k, 1]\n",
    "        heatmap = heatmap_k(x_k, y_k, k)\n",
    "        heatmaps.append(heatmap)\n",
    "    heatmaps = np.array(heatmaps).reshape((64, 64, 68))\n",
    "    return heatmaps\n",
    "\n",
    "def preprocess(img, landmarks):\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    detections = face_detector(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    boxes = [[d.left(), d.top(), d.right(), d.bottom()] for d in detections]\n",
    "\n",
    "    resized_img = None\n",
    "    resized_landmarks = None\n",
    "    heatmaps = None\n",
    "\n",
    "    # Task 1: Preprocess image using dlib\n",
    "    if img is not None :\n",
    "        if len(detections) == 0:\n",
    "            return None\n",
    "        d = detections[0]\n",
    "        crop = img[d.top():d.bottom(), d.left():d.right()]\n",
    "        resized_img = cv2.resize(crop, (int(256), int(256)))\n",
    "\n",
    "    # Task 2: Preprocess ground truth landmarks\n",
    "    if landmarks is not None:\n",
    "        resize_ratio = 256/d.width()\n",
    "        translate = np.array([d.left(), d.top()])\n",
    "        resized_landmarks = np.round(resize_ratio * (landmarks - translate))\n",
    "        heatmaps = generate_heatmaps(resized_landmarks)\n",
    "\n",
    "    return (resized_img, resized_landmarks, heatmaps)\n",
    "\n",
    "def batch_preprocess(img_data, landmark_data, n):\n",
    "    counter = 0\n",
    "    img_store = []\n",
    "    hm_store = []\n",
    "    ind_store = []\n",
    "    for index, (img, lm) in enumerate(zip(img_data, landmark_data)):\n",
    "        processed_data = preprocess(img, lm)\n",
    "        if processed_data:\n",
    "            (resized_img, resized_landmarks, heatmaps) = processed_data\n",
    "            img_store.append(resized_img)\n",
    "            hm_store.append(heatmaps)\n",
    "            ind_store.append(index)\n",
    "            counter += 1\n",
    "        if counter >= n:\n",
    "            break\n",
    "    return (np.array(img_store), np.array(hm_store), ind_store)\n",
    "\n",
    "def plot_loss(history, filename):\n",
    "    plt.plot(history.history['loss'], label='Training')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def train(model, X_train, Y_train, X_val, Y_val):\n",
    "    X_train = tf.convert_to_tensor(X_train/255.0, dtype=tf.float64)\n",
    "    Y_train = tf.convert_to_tensor(Y_train, dtype=tf.float64)\n",
    "    X_val = tf.convert_to_tensor(X_val/255.0, dtype=tf.float64)\n",
    "    Y_val = tf.convert_to_tensor(Y_val, dtype=tf.float64)\n",
    "\n",
    "    # Format the labels correctly for 2D-FAN\n",
    "    Y_train = [Y_train for i in range(4)]\n",
    "    Y_val = [Y_val for i in range(4)]\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train, Y_train, epochs=30, validation_data=(X_val, Y_val))\n",
    "    plot_loss(history, 'train_val_loss.png')\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_visual(img_data, lm_xs, lm_ys, filename):\n",
    "    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_data)\n",
    "    plt.scatter(lm_xs, lm_ys, c='r', marker='.')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test):\n",
    "    img = tf.convert_to_tensor(X_test/255.0, dtype=tf.float64)\n",
    "    preds = model(img)\n",
    "\n",
    "    # Use 4th hourglass module element as heatmap prediction\n",
    "    # preds[i] has shape: (1, 64, 64, 68), heatmap_preds has shape: (64, 64, 68)\n",
    "    heatmap_preds = preds[3][0, :, :, :] #TODO: change this to 3 after training\n",
    "    # print(heatmap_preds.shape)\n",
    "\n",
    "    # Argmax to convert heatmaps to landmarks\n",
    "    landmark_preds = []\n",
    "    for k in range(heatmap_preds.shape[2]):\n",
    "        heatmap_pred = heatmap_preds[:, :, k]\n",
    "        ind = np.unravel_index(np.argmax(heatmap_pred, axis=None), heatmap_pred.shape)\n",
    "        landmark_preds.append(list(ind))\n",
    "    landmark_preds = np.array(landmark_preds)\n",
    "    # print(landmark_preds.shape)\n",
    "    return landmark_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fan\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "base (Sequential)            multiple                  478208    \n",
      "_________________________________________________________________\n",
      "hg_0 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "hg_1 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "hg_2 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "hg_3 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "l0 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "l1 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "l2 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "l3 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "al0 (Conv2D)                 multiple                  17664     \n",
      "_________________________________________________________________\n",
      "al1 (Conv2D)                 multiple                  17664     \n",
      "_________________________________________________________________\n",
      "al2 (Conv2D)                 multiple                  17664     \n",
      "_________________________________________________________________\n",
      "bl0 (Conv2D)                 multiple                  65792     \n",
      "_________________________________________________________________\n",
      "bl1 (Conv2D)                 multiple                  65792     \n",
      "_________________________________________________________________\n",
      "bl2 (Conv2D)                 multiple                  65792     \n",
      "=================================================================\n",
      "Total params: 23,874,320\n",
      "Trainable params: 5,773,380\n",
      "Non-trainable params: 18,100,940\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "model = init_model()\n",
    "\n",
    "# Task 2 (see load_data.py)\n",
    "results = load_data()\n",
    "\n",
    "# Task 3\n",
    "# Prepare data for training\n",
    "(X_train, Y_train, ind_train) = batch_preprocess(results['images_train'], results['landmarks_train'], 16)\n",
    "(X_val, Y_val, ind_val) = batch_preprocess(results['images_val'], results['landmarks_val'], 2)\n",
    "(X_test, Y_test, ind_test) = batch_preprocess(results['images_test'], results['landmarks_test'], 1)\n",
    "#print(X_train.shape, Y_train.shape)\n",
    "#print(X_val.shape, Y_val.shape)\n",
    "#print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2 samples\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 24s 1s/sample - loss: 0.2842 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.2779 - val_loss: 3.2957 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 3.2874\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 11s 677ms/sample - loss: 0.1609 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.1546 - val_loss: 1.7102 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 1.7019\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 11s 690ms/sample - loss: 0.0891 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0828 - val_loss: 1.2073 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 1.1989\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 11s 698ms/sample - loss: 0.0512 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0449 - val_loss: 0.9747 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.9663\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 11s 697ms/sample - loss: 0.0388 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0325 - val_loss: 0.8435 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.8351\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 11s 708ms/sample - loss: 0.0334 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0270 - val_loss: 0.7618 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.7534\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 11s 696ms/sample - loss: 0.0299 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0236 - val_loss: 0.6998 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.6914\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 11s 696ms/sample - loss: 0.0271 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0208 - val_loss: 0.6257 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.6174\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 11s 696ms/sample - loss: 0.0244 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0181 - val_loss: 0.5347 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.5263\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 11s 716ms/sample - loss: 0.0218 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0155 - val_loss: 0.4362 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.4278\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 11s 697ms/sample - loss: 0.0195 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0132 - val_loss: 0.3399 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.3315\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 11s 697ms/sample - loss: 0.0175 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0112 - val_loss: 0.2566 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.2482\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 11s 707ms/sample - loss: 0.0159 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0096 - val_loss: 0.1920 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.1836\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 11s 695ms/sample - loss: 0.0146 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0083 - val_loss: 0.1453 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.1369\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 11s 689ms/sample - loss: 0.0137 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0073 - val_loss: 0.1120 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.1036\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 11s 698ms/sample - loss: 0.0128 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0065 - val_loss: 0.0876 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0792\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 11s 709ms/sample - loss: 0.0119 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0056 - val_loss: 0.0694 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0611\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 11s 694ms/sample - loss: 0.0112 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0049 - val_loss: 0.0557 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0473\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 11s 693ms/sample - loss: 0.0106 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0043 - val_loss: 0.0452 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0368\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 11s 695ms/sample - loss: 0.0102 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0039 - val_loss: 0.0373 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0290\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 11s 696ms/sample - loss: 0.0099 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0035 - val_loss: 0.0315 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0231\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 11s 697ms/sample - loss: 0.0096 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0033 - val_loss: 0.0272 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0188\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 11s 704ms/sample - loss: 0.0095 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0031 - val_loss: 0.0239 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0155\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 11s 716ms/sample - loss: 0.0093 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0030 - val_loss: 0.0212 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0129\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 11s 699ms/sample - loss: 0.0092 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0029 - val_loss: 0.0191 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0107\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 11s 709ms/sample - loss: 0.0090 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0027 - val_loss: 0.0173 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0089\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 11s 694ms/sample - loss: 0.0089 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0025 - val_loss: 0.0158 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "16/16 [==============================] - 11s 696ms/sample - loss: 0.0087 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0024 - val_loss: 0.0146 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0063\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 11s 687ms/sample - loss: 0.0085 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0022 - val_loss: 0.0137 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0053\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 11s 699ms/sample - loss: 0.0084 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0020 - val_loss: 0.0130 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "# Task 4\n",
    "model = train(model, X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 5\n",
    "landmark_preds = test(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = results['images_test'][ind_test[0]]\n",
    "orig_lms = results['landmarks_test'][ind_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box size for test image for rescaling up\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "detections = face_detector(cv2.cvtColor(orig_img, cv2.COLOR_BGR2GRAY))\n",
    "d = detections[0]\n",
    "\n",
    "# Plot predicted landmarks on original image\n",
    "resize_ratio = d.width()/64\n",
    "translate = np.array([d.left(), d.top()])\n",
    "resized_landmarks = np.round((resize_ratio * landmark_preds) + translate)\n",
    "plot_visual(orig_img, resized_landmarks[:, 0], resized_landmarks[:, 1], 'test_predlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional ground truth landmark plot\n",
    "plot_visual(orig_img, orig_lms[:, 0], orig_lms[:, 1], 'test_gtlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on 256 x 256 ground truth landmark plot and pred landmark plot\n",
    "# (resized_img, resized_lms, heatmaps) = preprocess(orig_img, orig_lms)\n",
    "# resize_ratio = 256/64\n",
    "# resized_landmarks = resize_ratio * landmark_preds\n",
    "# plot_visual(resized_img, resized_lms[:, 0], resized_lms[:, 1], 'test_smallgtlm_plot.png')\n",
    "# plot_visual(X_test[0, :, :, :], resized_landmarks[:, 0], resized_landmarks[:, 1], 'test_smallpredlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extra Credit\n",
    "sanders_img = cv2.imread('sanders.png')\n",
    "sanders_test = np.array([preprocess(sanders_img, None)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanders_landmark_preds = test(model, sanders_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box size for sanders image for rescaling up\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "detections = face_detector(cv2.cvtColor(sanders_img, cv2.COLOR_BGR2GRAY))\n",
    "d = detections[0]\n",
    "\n",
    "# Plot predicted landmarks on original image\n",
    "resize_ratio = d.width()/64\n",
    "translate = np.array([d.left(), d.top()])\n",
    "resized_landmarks = np.round((resize_ratio * sanders_landmark_preds) + translate)\n",
    "plot_visual(sanders_img, resized_landmarks[:, 0], resized_landmarks[:, 1], 'sanders_predlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
