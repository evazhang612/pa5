{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model import *\n",
    "from load_data import *\n",
    "import dlib\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # Task 1 \n",
    "    model = FAN(4)\n",
    "    model.build((1,256,256,3))\n",
    "    model.load_weights(\"tf_fan_2D_3layers.h5\")\n",
    "\n",
    "    model.base.trainable = False # Freezes the weights for the base module\n",
    "    for i in range(3):\n",
    "        # TODO: Freeze the weights for the first 3 hourglass modules\n",
    "        # Each hourglass module is composed of elements from\n",
    "        # model.hgs, model.ls, model.split_as, model.split_bs\n",
    "        model.hgs[i].trainable = False \n",
    "        model.ls[i].trainable = False \n",
    "        model.split_as[i].trainable = False \n",
    "        model.split_bs[i].trainable = False \n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def heatmap_k(x_k, y_k, k):\n",
    "    return np.array([math.exp(-((x - x_k)**2 + (y - y_k)**2)) for x in range(64) for y in range(64)]).reshape((64, 64))\n",
    "\n",
    "def generate_heatmaps(resized_landmarks):\n",
    "    resize_ratio = 64/256\n",
    "    heatmap_landmarks = np.round(resize_ratio * resized_landmarks)\n",
    "    heatmaps = []\n",
    "    for k in range(heatmap_landmarks.shape[0]):\n",
    "        x_k = heatmap_landmarks[k, 0]\n",
    "        y_k = heatmap_landmarks[k, 1]\n",
    "        heatmap = heatmap_k(x_k, y_k, k)\n",
    "        heatmaps.append(heatmap)\n",
    "    heatmaps = np.array(heatmaps).reshape((64, 64, 68))\n",
    "    return heatmaps\n",
    "\n",
    "def preprocess(img, landmarks):\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    detections = face_detector(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    boxes = [[d.left(), d.top(), d.right(), d.bottom()] for d in detections]\n",
    "\n",
    "    resized_img = None\n",
    "    resized_landmarks = None\n",
    "    heatmaps = None\n",
    "\n",
    "    # Task 1: Preprocess image using dlib\n",
    "    if img is not None :\n",
    "        if len(detections) == 0:\n",
    "            return None\n",
    "        d = detections[0]\n",
    "        crop = img[d.top():d.bottom(), d.left():d.right()]\n",
    "        resized_img = cv2.resize(crop, (int(256), int(256)))\n",
    "\n",
    "    # Task 2: Preprocess ground truth landmarks\n",
    "    if landmarks is not None:\n",
    "        resize_ratio = 256/d.width()\n",
    "        translate = np.array([d.left(), d.top()])\n",
    "        resized_landmarks = np.round(resize_ratio * (landmarks - translate))\n",
    "        heatmaps = generate_heatmaps(resized_landmarks)\n",
    "\n",
    "    return (resized_img, resized_landmarks, heatmaps)\n",
    "\n",
    "def batch_preprocess(img_data, landmark_data, n):\n",
    "    counter = 0\n",
    "    img_store = []\n",
    "    hm_store = []\n",
    "    ind_store = []\n",
    "    for index, (img, lm) in enumerate(zip(img_data, landmark_data)):\n",
    "        processed_data = preprocess(img, lm)\n",
    "        if processed_data:\n",
    "            (resized_img, resized_landmarks, heatmaps) = processed_data\n",
    "            img_store.append(resized_img)\n",
    "            hm_store.append(heatmaps)\n",
    "            ind_store.append(index)\n",
    "            counter += 1\n",
    "        if counter >= n:\n",
    "            break\n",
    "    return (np.array(img_store), np.array(hm_store), ind_store)\n",
    "\n",
    "def plot_loss(history, filename):\n",
    "    plt.plot(history.history['loss'], label='Training')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def train(model, X_train, Y_train, X_val, Y_val):\n",
    "    X_train = tf.convert_to_tensor(X_train/255.0, dtype=tf.float64)\n",
    "    Y_train = tf.convert_to_tensor(Y_train, dtype=tf.float64)\n",
    "    X_val = tf.convert_to_tensor(X_val/255.0, dtype=tf.float64)\n",
    "    Y_val = tf.convert_to_tensor(Y_val, dtype=tf.float64)\n",
    "\n",
    "    # Format the labels correctly for 2D-FAN\n",
    "    Y_train = [Y_train for i in range(4)]\n",
    "    Y_val = [Y_val for i in range(4)]\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train, Y_train, epochs=30, validation_data=(X_val, Y_val))\n",
    "    plot_loss(history, 'train_val_loss.png')\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_visual(img_data, lm_xs, lm_ys, filename):\n",
    "    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_data)\n",
    "    plt.scatter(lm_xs, lm_ys, c='r', marker='.')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test, i):\n",
    "    img = tf.convert_to_tensor(np.expand_dims(X_test[i], axis=0)/255.0, dtype=tf.float64)\n",
    "    preds = model(img)\n",
    "\n",
    "    # preds[i] has shape: (1, 64, 64, 68), heatmap_preds has shape: (64, 64, 68)\n",
    "    heatmap_preds = preds[-2][0, :, :, :]\n",
    "    # print(heatmap_preds.shape)\n",
    "\n",
    "    # Argmax to convert heatmaps to landmarks\n",
    "    landmark_preds = []\n",
    "    for k in range(heatmap_preds.shape[2]):\n",
    "        heatmap_pred = heatmap_preds[:, :, k]\n",
    "        ind = np.unravel_index(np.argmax(heatmap_pred, axis=None), heatmap_pred.shape)\n",
    "        landmark_preds.append(list(ind))\n",
    "    landmark_preds = np.array(landmark_preds)\n",
    "    # Swap x and y indices on landmarks since we're taking 3rd hourglass element\n",
    "    landmark_preds[:, [0, 1]] = landmark_preds[:, [1, 0]]\n",
    "    # print(landmark_preds.shape)\n",
    "    return landmark_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fan_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "base (Sequential)            multiple                  478208    \n",
      "_________________________________________________________________\n",
      "hg_0 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "hg_1 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "hg_2 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "hg_3 (Sequential)            multiple                  5768960   \n",
      "_________________________________________________________________\n",
      "l0 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "l1 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "l2 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "l3 (Conv2D)                  multiple                  17476     \n",
      "_________________________________________________________________\n",
      "al0 (Conv2D)                 multiple                  17664     \n",
      "_________________________________________________________________\n",
      "al1 (Conv2D)                 multiple                  17664     \n",
      "_________________________________________________________________\n",
      "al2 (Conv2D)                 multiple                  17664     \n",
      "_________________________________________________________________\n",
      "bl0 (Conv2D)                 multiple                  65792     \n",
      "_________________________________________________________________\n",
      "bl1 (Conv2D)                 multiple                  65792     \n",
      "_________________________________________________________________\n",
      "bl2 (Conv2D)                 multiple                  65792     \n",
      "=================================================================\n",
      "Total params: 23,874,320\n",
      "Trainable params: 5,773,380\n",
      "Non-trainable params: 18,100,940\n",
      "_________________________________________________________________\n",
      "(7, 256, 256, 3) (7, 64, 64, 68)\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "model = init_model()\n",
    "\n",
    "# Task 2 (see load_data.py)\n",
    "results = load_data()\n",
    "\n",
    "# Task 3\n",
    "# Prepare data for training\n",
    "(X_train, Y_train, ind_train) = batch_preprocess(results['images_train'], results['landmarks_train'], 16)\n",
    "(X_val, Y_val, ind_val) = batch_preprocess(results['images_val'], results['landmarks_val'], 2)\n",
    "(X_test, Y_test, ind_test) = batch_preprocess(results['images_test'], results['landmarks_test'], 7)\n",
    "#print(X_train.shape, Y_train.shape)\n",
    "#print(X_val.shape, Y_val.shape)\n",
    "#print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 2 samples\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 23s 1s/sample - loss: 0.2842 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.2779 - val_loss: 3.2954 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 3.2870\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 12s 772ms/sample - loss: 0.1609 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.1546 - val_loss: 1.7099 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 1.7016\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 13s 782ms/sample - loss: 0.0891 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0828 - val_loss: 1.2104 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 1.2020\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 13s 796ms/sample - loss: 0.0512 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0449 - val_loss: 0.9801 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.9717\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 13s 801ms/sample - loss: 0.0388 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0324 - val_loss: 0.8500 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.8417\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 13s 821ms/sample - loss: 0.0334 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0270 - val_loss: 0.7692 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.7608\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 17s 1s/sample - loss: 0.0299 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0236 - val_loss: 0.7077 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.6993\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 15s 946ms/sample - loss: 0.0271 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0208 - val_loss: 0.6332 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.6249\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 13s 808ms/sample - loss: 0.0244 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0181 - val_loss: 0.5406 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.5323\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 13s 787ms/sample - loss: 0.0218 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0155 - val_loss: 0.4402 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.4318\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 13s 795ms/sample - loss: 0.0195 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0132 - val_loss: 0.3425 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.3341\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 13s 786ms/sample - loss: 0.0175 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0112 - val_loss: 0.2584 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.2500\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 13s 801ms/sample - loss: 0.0159 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0096 - val_loss: 0.1932 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.1848\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 13s 792ms/sample - loss: 0.0146 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0083 - val_loss: 0.1460 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.1377\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 13s 789ms/sample - loss: 0.0137 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0073 - val_loss: 0.1125 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.1041\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 13s 800ms/sample - loss: 0.0128 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0065 - val_loss: 0.0879 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0795\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 13s 815ms/sample - loss: 0.0119 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0056 - val_loss: 0.0697 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0613\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 13s 810ms/sample - loss: 0.0112 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0049 - val_loss: 0.0559 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0475\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 13s 827ms/sample - loss: 0.0106 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0043 - val_loss: 0.0454 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0370\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 13s 801ms/sample - loss: 0.0102 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0039 - val_loss: 0.0375 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0291\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 13s 808ms/sample - loss: 0.0099 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0035 - val_loss: 0.0316 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0233\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 13s 798ms/sample - loss: 0.0096 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0033 - val_loss: 0.0273 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0189\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 13s 839ms/sample - loss: 0.0095 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0031 - val_loss: 0.0239 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0156\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 13s 800ms/sample - loss: 0.0093 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0030 - val_loss: 0.0213 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0129\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 15s 934ms/sample - loss: 0.0092 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0029 - val_loss: 0.0191 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0108\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 14s 844ms/sample - loss: 0.0090 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0027 - val_loss: 0.0173 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0090\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 14s 851ms/sample - loss: 0.0089 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0025 - val_loss: 0.0158 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "16/16 [==============================] - 13s 805ms/sample - loss: 0.0087 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0024 - val_loss: 0.0146 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0063\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 14s 878ms/sample - loss: 0.0085 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0022 - val_loss: 0.0137 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0053\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 14s 870ms/sample - loss: 0.0084 - output_1_loss: 0.0020 - output_2_loss: 0.0021 - output_3_loss: 0.0023 - output_4_loss: 0.0020 - val_loss: 0.0130 - val_output_1_loss: 0.0029 - val_output_2_loss: 0.0027 - val_output_3_loss: 0.0028 - val_output_4_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "# Task 4\n",
    "model = train(model, X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 5\n",
    "landmark_preds = test(model, X_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = results['images_test'][ind_test[4]]\n",
    "test_lms = results['landmarks_test'][ind_test[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box size for test image for rescaling up\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "detections = face_detector(cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY))\n",
    "d = detections[0]\n",
    "\n",
    "# Plot predicted landmarks on original image\n",
    "resize_ratio = d.width()/64\n",
    "translate = np.array([d.left(), d.top()])\n",
    "resized_landmarks = np.round((resize_ratio * landmark_preds) + translate)\n",
    "plot_visual(test_img, resized_landmarks[:, 0], resized_landmarks[:, 1], 'test_predlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional ground truth landmark plot\n",
    "plot_visual(test_img, test_lms[:, 0], test_lms[:, 1], 'test_gtlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on 256 x 256 ground truth landmark plot and pred landmark plot\n",
    "# (resized_img, resized_lms, heatmaps) = preprocess(orig_img, orig_lms)\n",
    "# resize_ratio = 256/64\n",
    "# resized_landmarks = resize_ratio * landmark_preds\n",
    "# plot_visual(resized_img, resized_lms[:, 0], resized_lms[:, 1], 'test_smallgtlm_plot.png')\n",
    "# plot_visual(X_test[0, :, :, :], resized_landmarks[:, 0], resized_landmarks[:, 1], 'test_smallpredlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extra Credit\n",
    "mulaney_img = cv2.imread('mulaney.png')\n",
    "mulaney_test = np.array([preprocess(mulaney_img, None)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mulaney_landmark_preds = test(model, mulaney_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box size for sanders image for rescaling up\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "detections = face_detector(cv2.cvtColor(mulaney_img, cv2.COLOR_BGR2GRAY))\n",
    "d = detections[0]\n",
    "\n",
    "# Plot predicted landmarks on original image\n",
    "resize_ratio = d.width()/64\n",
    "translate = np.array([d.left(), d.top()])\n",
    "resized_landmarks = np.round((resize_ratio * mulaney_landmark_preds) + translate)\n",
    "plot_visual(mulaney_img, resized_landmarks[:, 0], resized_landmarks[:, 1], 'mulaney_predlm_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
